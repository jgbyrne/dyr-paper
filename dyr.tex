\documentclass[10pt,journal,compsoc]{IEEEtran}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{cite}

\usepackage[pdftex]{graphicx}
\graphicspath{./figures/}

\usepackage{amsthm, amsmath, amsfonts}
\interdisplaylinepenalty=2500

\usepackage{algorithmic}
\usepackage{array}
\usepackage{url}

\hyphenation{}

\newcommand{\ts}{\textsuperscript}

\begin{document}
\title{Dyr, a Program for Bayesian Inference of Language Phylogenies}

\author{Student Name: J.G. Byrne\\Supervisor Name: Professsor M.J.R. Bordewich\\
Submitted as part of the degree of MEng Computer Science to the\\
Board of Examiners in the Department of Computer Sciences, Durham University
}


\markboth{DURHAM UNIVERSITY, DEPARTMENT OF COMPUTER SCIENCE}%
{Shell \MakeLowercase{\textit{et al.}}}

\IEEEtitleabstractindextext{%
\begin{abstract}
    Bayesian statistics provide a powerful framework for inferring the evolutionary history of language families from lexical data, a problem which is made computationally tractable by Markov Chain Monte Carlo (MCMC) algorithms. We present Dyr, a simple yet capable new system for Bayesian inference, and use it to replicate state-of-the-art results in the field of Indo-European linguistics. 
\end{abstract}

\begin{IEEEkeywords}
Bayesian Inference, Markov Processes, Linguistics, Indo-European
\end{IEEEkeywords}}

\maketitle
\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}

\IEEEPARstart{L}{anguages} evolve over time. Some of these changes are phonetic or grammatical, but many are lexical (changes in the vocabulary). Words are forgotten and replaced, sometimes by other words that have changed meaning, and sometimes by borrowings from other languages.\footnote{For example, the Old English word \textit{dēor} was displaced by the French 'animal', and survives only in the narrower sense 'deer'. However, the equivalent word in Danish, \textit{dyr}, whence this project name, retains the older meaning. Both words derive from Proto-Germanic \textit{*deuzą}, ultimately from Proto-Indo-European \textit{*d\ts{h}wes}, meaning 'breath'.} Occasionally, some speakers of a language will come to speak so differently to the others that the groups can no longer understand each other, and the language splits in two.

Scholars have noticed similarities between languages for millenia. In the 18\ts{th} century, the field of comparative linguistics was born, which seeks to systematically reconstruct the historical relationships between languages. The early comparative linguists observed that while languages can evolve, sunder, and go extinct, they rarely merge, and are never created anew. Therefore, from the 19\ts{th} century onwards it became \textit{de rigeur} to describe language descent with evolutionary trees, or `phylogenies', and though not without criticism, this model remains predominant in linguistics to this day.

Historically, constructing phylogenies has been a job for humans, being based on the judgement of expert scholars with deep knowledge of languages ancient and modern. Although fruitful, this approach is naturally susceptible to human biases and oversights. It also provides no way to determine the age of unattested ancestor languages other than the (admittedly finely-honed) intuition of learned intellectuals.

The problem of ancestral dating is of particular relevance to Indo-European, the largest and most studied language family in the world. Encompassing nearly all of the languages of Europe and a great many in Western Asia and India, the challenge of reconstructing the history of this vast grouping has captivated comparative linguists since the advent of the discipline. And yet, one central question is yet to be conclusively answered: where and when was Proto-Indo-European (PIE; the ancestor of all Indo-European languages) originally spoken? Two main theories abound. The first, known as the `Kurgan' hypothesis, postulates an \textit{Urheimat} (original homeland) in the Pontic-Caspian steppe north of the Black Sea\cite{gimbutas1974gods}.\footnote{A \textit{kurgan} is a tumulus or burial mound. This theory is associates the spread of Indo-European with warlike tumulus-building charioteers.} Conversely, the second proposes an origin in Anatolia\cite{renfrew2001anatolian}.\footnote{This rather more sedate theory suggests a gradual proliferation of Indo-European in tandem with the spread of agriculture} The crucial difference between the two theories is that while the former ascribes a time depth of 6000 years to PIE, the latter hinges on it being considerably more ancient, at approximately 8500 years old. A reliable estimate for the age of PIE - that is, the root age of the Indo-European language tree - could therefore be potent evidence for one theory over the other.

Since the millenium, researchers have adopted a new method to analyse language families in general and Indo-European in particular -- Bayesian inference. By re-appropriating software designed to analyse genetic data and construct biological evolutionary trees, they have successfully inferred plausible dated phylogenies from large vocabulary databases. Such research feels tantalisingly close to an objective solution to linguistic enigmas such as that of Indo-European provenance.

However, in reality, the human factor still plays a role. Bayesian inference requires the specification of prior distributions, the choice of which can radically affect the results of the computation. For research to be rigorous and reliable, priors should be chosen carefully and properly justified.

Yet much study in the relatively small field of `Bayesian Phylolinguistics' falls short of this mark. Priors are often chosen seemingly out of habit or convention. Such laxness poses particular danger when these conventions have their origins in bioinformatics; a model which is sensible in the context of biological evolution may not be so logical when applied to languages.

We suggest that one reason for this tendency is the continued reliance on large, featureful bioinformatics software packages like BEAST2 and MrBayes. Any dedicated support for linguistics in these programs tends to be something of an afterthought, and their intimidating size makes them hard to understand in their totality. Therefore, we submit that to step out of the shadow of the older, larger discipline, it is desirable for Bayesian phylolinguistics to have its own dedicated software package.

We thusly present \textit{Dyr}, a new program for Bayesian inference of linguistic phylogenies. Small enough that its source code may be read and understood in a day, and offering only the features required for linguistic analysis, \textit{Dyr} is nonetheless built to be flexible and extensible. Capable of replicating state-of-the-art results in Bayesian Phylolinguistics, our hope and intention is that \textit{Dyr} can serve as a worthy platform for trialling novel methods with sound linguistic justification.

\section{Related Work}

The first serious attempt to use statistical methods to investigate language phylogenies was made by Morris Swadesh in the 1950s. His `glottochronology' model -- which assumed a constant global rate of change -- had limited practical utility, but his ideas were foundational to more sophisticated subsequent attempts.\cite{swadesh1955towards} In particular, the concept of the Swadesh list, a collation of basic and universal word-semantics underlies the lexical trait analysis used in quantitative historical linguistics today, including in this report.
\subsection{Inferring Indo-European}

The first notable paper to use the Markov Chain Monte Carlo (MCMC) technique to infer the posterior distribution of a linguistic phylogeny was Gray and Atkinson's groundbreaking 2003 study. Their analysis of the Indo-European family, which employed the forerunner of the modern IELEX dataset, yielded robust support for the Anatolian hypothesis.\cite{gray2003language} This research was reinforced by the later results of Bouckaert et al.\cite{bouckaert2012mapping}\cite{bouckaert2013correction}, who used an updated dataset, and tested an alternative trait model devised by Nicholls and Gray\cite{nicholls2008dated} requiring that cognate traits arise just once in a phylogeny, again finding strongest support for an Anatolian origin.

This trend was bucked by Chang et al., who built upon the work of Bouckaert et al. with the key addition of novel prior constraints on tree topology.\cite{chang2015ancestry} In particular, they mandated that certain languages be effectively ancestral to others in the tree; for example, Old English is necessarily positioned as a direct ancestor to English. Their intention was to correct for a phenomenon that they dubbed `jogging'. Without ancestry constraints, an ancestral interior node will be postulated that is older than both a modern language and its more ancient ancestor. Consequently the `traversal distance' between the two languages will be substantially longer than should actually be the case. This causes the Bayesian process to infer generally lower evolutionary rates and thus an older root age for the tree. With these constraints imposed, and with some fixes applied to the Bouckaert et al. dataset, Chang et al. found the strongest support for the Steppe hypothesis.

Since the publication of the Chang et al. study, futher research has questioned the necessity of such constraints. Rama suggested that similar results to those obtained by Chang et al. could be obtained without ancestry constraints by usage of a Uniform tree prior.\cite{rama2018three} Rama astutely observed that the population size parameter of the Coalescent prior does not have an obvious interpretation in the context of language evolution, but neglected to apply the same standard of justifiability to the Uniform prior. This is in spite of the clear pitfalls of the Uniform prior; namely, that it implies a language family evolves as a collective whole, rather than evolution being a process happening largely independantly in each individual language. However, his work does serve to highlight the potential for further investigation into the bread-and-butter of phylogenetic inference; prior distributions and substitution models. In particular we believe Rama's work demonstrates a neccessity for research into tree prior models that are both empirically successful at replicating validated results and also have sound linguistic justification. 

\subsection{Extant Software}

Bayesian phylogenetic inference is dominated by two large software packages, MrBayes\cite{ronquist2012mrbayes} and BEAST 2\cite{bouckaert2014beast}. The former is written in C while the latter uses Java -- languages which lack features that many modern programmers value, such as Algebraic Data Types. Both libaries are extremely featureful, but many features are inappropriate in a linguistics context or are simply inapplicable. The size of these software packages makes them hard to study and modify; for example, MrBayes has nearly 100,000 lines of C code, of which 20,000 is the MCMC implementation alone.

Both BEAST 2 and MrBayes were originally written with Bioinformaticians as the target users; to my knowledge \textit{Dyr} is the first Bayesian inference package designed from the ground-up with phylolinguistics as the primary use-case. \textit{Dyr} follows the lead of both these software packages by using the BEAGLE3 library for hardware-accelerated computation of likelihoods.\cite{ayres2019beagle}

\section{Methods}

The aim of phylogenetic inference is to learn which phylogenies (dated trees) are most likely given a particular evolutionary model and a set of known data. This is known as the `posterior likelihood'. In a linguistics context, the known data is typically `lexical trait data' -- that is, information about the vocabulary of the languages in question. The evolutionary model, which in Bayesian terms provides our `prior likelihood', encapsulates our beliefs about how likely languages are to diverge and how rapidly their vocabulary changes. To allow our inferred phylogeny to best fit the signal present in the data, we also infer some parameters of our evolutionary model, though these too are subject to their own prior likelihood distributions.

The space of possible parameterisations is very large and it is not typically feasible to derive a // TODO WRONG closed-form expression for the posterior likelihood distribution. However, Bayes' theorem allows us to assess the posterior likelihood of any specific choice of parameterisation given the data. We therefore use a stochastic process called Markov Chain Monte Carlo (MCMC) to iteratively step-through the space of possible parameterisations, with a preference for augmentations to the parameterisation that improve the posterior likelihood. It is provable that the long-run outcome of this process will be to simulate the desired posterior distribution.

\subsection{Lexical Trait Data}

The primary evidence used to infer linguistic phylogenies is lexical trait data. In principle, many different linguistic features could be appropriated to inform Bayesian inference, but for both principled and pragmatic reasons the vast majority of analyses use lexical data. In particular, the class of traits used in our datasets is what Chang et al. termed \textsc{Root Meaning} traits. These traits can be described as tuples in the form (\textit{ root },\;\texttt{semantic}\;). A \textsc{Root Meaning} trait is binary; either present or absent for a given language. A given trait is present in a language if that language has a common word for the \texttt{semantic} that derives from the \textit{root}. For example, the Irish word for a \texttt{fish} is `iasc', which like the English `fish', comes from the Indo-European root \textit{*peysk-}. So the trait (\textit{ *peysk- },\;\texttt{fish}\;) is present in both Irish and English. However the Greek word for \texttt{fish} is `ikhthus', which is believed to derive from the root \textit{*d\ts{h}g\ts{h}u-}. Therefore the trait is absent in Greek.

From a great many such traits is constructed the IELEX database, the gold-standard source of lexical data for Indo-European, upon which we shall found our analyses. In particular, we use the subsets of IELEX constructed by Chang et al., termed \textsc{Narrow}, \textsc{Medium}, and \textsc{Broad}, containing 52, 82, and 94 languages respectively. In our inferences, these languages will correspond to leaves in our phylogenies.

\subsection{Defining the Posterior Distribution}

Bayes' theorem is stated as follows:
\begin{equation}
    Pr(A\;|\;B) = \frac{Pr(B\;|\;A) \cdot Pr(A)}{Pr(B)}
\end{equation}

In the context of phylogenetic inference, we seek to infer the probability distribution of possible parameterisations given the observed data. Therefore $Pr(B)$ corresponds to $Pr(x)$, the probability of the trait data, which is by definition equal to $1$ since it has been observed. Meanwhile, $Pr(A)$ corresponds to $Pr(\Gamma)$, the prior likelihood of a given parameterisation. We define $\Gamma$ more thoroughly below:
\begin{align*}
    \Gamma &= (\psi, \omega, \lambda)\\
    \psi   &= \text{parameters describing a dated tree}\\
    \omega &= \text{parameters of the prior model for dated trees}\\
    \lambda&= \text{parameters of the prior model for trait evolution}
\end{align*}
We thus derive equation \eqref{eqn:posterior}. The posterior likelihood is proportional to the likelihood of the data given the parameterisation multiplied by the prior likelihood of the parameterisation. This is a proportionality because we do not require that our prior distributions sum to $1$.
\begin{equation}\label{eqn:posterior}
    Pr(\Gamma\;|\; x) \propto Pr(x\;|\;\psi, \omega, \lambda) \cdot f(\psi\;|\;\omega) \cdot f(\omega) \cdot f(\lambda)
\end{equation}

We define $\psi = (\tau, \delta)$, where $\tau$ is the topology of the tree and $\delta$ is the branch lengths. We consider the node or nodes with the longest path from the root to be at $t = 0$ and therefore in the present day, while all other nodes are understood to be at some $t > 0$, corresponding to their distance from the present in years. Naturally, any interior node is required to be older than its children.

\subsection{Calculating Likelihood}

Although Bayes' theorem absolves us of the need to directly calculate the posterior, we must still calculate the likelihood of the data given the parameterisation. Conceptually speaking, this is the likelihood across all possible trait assignments (that is, a binary array of absences and presences) across all possible nodes of the tree of the observed trait data being evolved at the tips, under a given process of trait evolution we call the substitution model.

\subsubsection{Felsenstein's Algorithm}

At first glance, this calculation sounds intractable. However, it can in fact be computed, with a divide-and-conquer method called Felsenstein's algorithm. The procedure is fairly inutitive: for each trait, we first define the trait's likelihood at the tips, based on the observed data. Then we work our way up the tree, deriving the `partial' likelihoods at each interior node based on its two children, until we reach the root, where we can sum up a final likelihood for the trait across all assignments. The overall likelihood of the tree given the data is therefore simply the product across all traits.\cite{felsenstein2004inferring}

Equation \eqref{eqn:felsenstein} below gives a formal definition of Felsenstein's algorithm. We denote the likelihood of a node $x$ having state $t$ for the trait $i$ as $L_x^{i}(t)$, and it is defined separately for leaf nodes $\ell$ and for interior nodes $a$. It's worth remembering that for our purposes the set of states is simply $t \in \{0, 1\}$, but the algorithm is best understood in its full generality. When a leaf node $\ell$ has recorded data for trait $i$, the value $x_\ell^{i}\left[\;t\;\right]$ is $1.0$ for the observed state $t$ and $0.0$ otherwise. When instead, the data is missing, the likelihood is split evenly between all values of $t$. For an interior node $a$, the likelihood of having state $t$ for the trait $i$ is calculated based on the product of the sum likelihood across all possible ways $t$ can evolve along the branch to the left child $a$ and the equivalent calculation along the branch to the right child $b$. The evolution probability is the core calculation performed by the substitution model and is predicated on the parameters $\lambda$. Note how the likelihood is thus recursively `rolled-up' towards $r$, the root node of the tree.

\begin{equation}\label{eqn:felsenstein}
    \setlength{\jot}{12px}
    \begin{split}
        L_\ell^{i}(t) &= x_\ell^{i}\left[\;t\;\right] \\
        L_a^{i}(t) &= \left(\sum_uPr^i_{a,b}\left(u\,\vert\,t\right)L_b^{i}\left(u\right)\right)\left(\sum_vPr^i_{a,c}\left(v\,\vert\,t\right)L_c^{i}\left(v\right)\right) \\
        \mathcal{L}^{i} &= \sum_u \;\pi_u \cdot L_r^{i}\left(u\right) \\
        \mathcal{L} &= \prod_i \;\mathcal{L}^i
    \end{split}
\end{equation}

We denote the root likelihood across all states of trait $i$ as $\mathcal{L}^{i}$. The calculation required is a weighted average, with the weights being the stationary frequencies $\pi_u$, which will be discussed shortly along with the other parameters in $\lambda$.

Calculating the final root likelihood is then a simple matter of taking the product of all of the per-trait root likelihoods. This value, $\mathcal{L}$, is the value of the term $Pr(x\;|\;\psi, \omega, \lambda)$ in equation \eqref{eqn:posterior}.

\subsubsection{Substitution Model and Trait Evolution}

We now seek to explain how the substitution model is used to calculate the probability of a state $t$ evolving to a state $u$ along a given edge of a tree. Let us state upfront the parameters of the model:

\begin{align*}
    \lambda &= (\mu,\;\pi,\;\alpha,\;\beta,\;\phi)\\
    \mu &= \text{Substitution base rate}\\
    \pi &= \text{Stationary frequencies: } \pi_0, \pi_1 \in \left(0, 1\right) : \pi_0 + \pi_1 = 1.0\\
    \alpha &= \text{Shape for Among Site Rate Variation (ASRV)}\\
    \beta &= \text{Shape for Among Branch Rate Variation (ABRV)}\\
    \phi &= \text{ABRV Rate Assignments}
\end{align*}

The core of the substitution model is the rate matrix, which describes the rates at which states mutate into each other. These matrices can be quite complex, but we opt for the simplest choice, the Generalised Time Reversible (GTR) model.\footnote{Chang et al. calls this the Restriction Site Character (RSC) model; the two are equivalent in the case of binary traits.} We have already seen how the stationary frequencies $\pi_0$ and $\pi_1$ influence the likelihood calculation, but they are also at the heart of the binary GTR rate matrix. 
\begin{equation}
\textbf{Q} = \frac{1}{2\pi_0\pi_1} \begin{bmatrix}
-\pi_1 & \pi_1\\
\pi_0 & -\pi_0
\end{bmatrix} \text{ \ given that \ } \pi_0 + \pi_1 = 1.0
\end{equation}

As the length of time over which a trait evolves increases, the probability of it being in a state $u$ asymptopically approaches $\pi_u$, and the state it was initially in becomes irrelevant. To be more precise, for every branch $(a, b)$ in the tree $\psi$, for every trait $i$, the transition probabilities $Pr^i_{a,b}\left(u\,\vert\,t\right)$ are defined by the transition matrix $\textbf{P}^i_{a,b}$, where:

\begin{equation}
\textbf{P}^i_{a,b} = \exp\left(\textbf{Q} \cdot \delta_{a,b} \cdot \eta^i_{a,b}\right) \text{  \ where  \  } \eta^i_{a,b} = \mu \cdot \gamma_i \cdot \rho_{a,b}
\end{equation}

As previously stated, the value $\delta_{a,b}$ is the length (in years) of the branch $(a, b)$. The value $\eta^i_{a,b}$ is the rate for the trait $i$ on the branch $(a, b)$, calculated as the product of three rate parameters. The first rate,  $\mu$, is the base rate -- a global parameter that cancels out the units of the branch lengths and controls the overall rate of evolution. The second, $\gamma_i$, is the site rate,\footnote{The term `site' is a relic from bioinformatics, where traits typically correspond to specific sites on the genome} which is specific to this trait $i$. It is drawn from a Gamma distribution $\Gamma(\alpha, \frac{1}{\alpha})$. The third rate, $\rho_{a,b}$, is the branch rate, which is specific to this branch. It is drawn from a log-normal distribution $\log \mathcal{N}(-\frac{\beta^2}{2}, \beta^2)$. Both of these distributions have a mean of $1$, so regardless of their shapes the overall average rate is equal to $\mu$. The choices of distributions are partly informed by implementation pragamatics and partly by the flexibility in shape that can be attained by modfications to $\alpha$ and $\beta$. \footnote{This paragraph abstracts quite significantly over the specifics of how these rates are actually chosen, which shall be discussed later.}

At this point the reader may be questioning the necessity of allowing rates to vary both across sites and and across branches. However there is a strong justification for both laxities. Variation in site rate is necessary because words vary greatly in their volatility. Certain common words, in particular numerals, change incredibly rarely. Others are considerably more susceptible to replacement. Equally, branch rates must be variable because languages evolve at dramatically different rates. A failure to account for this fact was the downfall of much early research into quantitiative historical linguistics. The classic (though by no means sole) exemplar is the case of the Nordic languages; while Norwegians find Old Norse virtually incomprehensible, Icelanders can read it as easily as an Englishman can read Jane Austen. The reason for this is simply that the rate of change of Icelandic has been remarkably slow, while that of Norwegian has been reasonably fast.

\subsection{Prior Distributions}

The second part of equation \eqref{eqn:posterior} is the prior likelihood of the parameterisation. These terms express our baseline evolutionary model for phylogenies in general and language in particular.

The first prior term in \eqref{eqn:posterior} is $f(\psi\;|\;\omega)$, which expresses the prior likelihood of the tree $\psi$ conditioned on the set of parameters $\omega$. In turn, the parameters $\omega$ have their own prior distribution $f(\omega)$. Together, these terms fully implement the prior likelihood model for dated trees, informally known as the `tree prior'. The choice of tree prior is among the most impactful and contentious choices that a researcher needs to make when performing phylogenetic inference.

\subsubsection{Tree Constraints}

To be precise, the prior distribution over $\psi$ is actually composed of a general-purpose phylogenetic model and a set of dataset-specific constraints. We implement three such classes of constraints: tip calibrations, clade constraints, and ancestry constraints.

Tip calibrations constrain the ages of tips that are positioned at some depth in the past. They are implemented as windows of uniform prior density, with all times outside the window having zero prior likelihood. These calibrations are used to encode our convictions about the time periods in which ancient languages were used into the prior model, while giving the inference process freedom to infer the time-depth of these nodes if such a signal exists. As an example, in our Indo-European inferences, the well understood language of Old English has a relatively tight calibration window of (950, 1050) years before the present, while Tocharian B -- about which we know comparatively little -- has a wider window of (1200, 1500) years.

The second constraint class is clade constraints, which are improper priors that simply impose a very large likelihood penalty on topologies that do not contain a given clade. A clade, also known as a monophylectic group, is a set of taxa (i.e. languages) that are all more closely related to each other than they are to any other taxon. Intuitively, a clade is a group that can be pruned from the tree by snipping in exactly one place. Implementing such a constraint into a prior model is sensible when a clade has been established by scholars beyond any doubt.

The third constraint class is ancestory constraints, which are an extension of clade constraints that in addition to requiring that a specified set of taxa form a clade also nominate an additional taxon that is required to be their direct ancestor. Since taxa are exclusively assigned to tips it is not possible for a given taxon to be associated with an internal node of a phylogeny. However, it is possible to simulate ancestry by requiring the ancestral taxon to be joined to the internal node directly above its descendants' clade by a branch of negligable length. We achieve this by using extremely costly improper priors on the lengths of these branches.

We will return to the topic of constraints when we evaluate the suitability of different priors for phylolinguistic inference. For the time being, however, we set them aside. Just remember that whenever we say `tree prior', what we really mean is `prior model \textit{with constraints}'.

\subsubsection{Coalescent Priors}

In our research we focus mainly on a tree prior described by Drummond et al. in a 2005 paper. This paper provides a Bayesian methodology for sampling a tree model called the `generalized skyline plot'. For brevity we refer to this methodology as the `Bayesian skyline'. The theoretical basis for the generalised skyline plot is a stochastic process known as `coalescent theory', and for this reason the Drummond et al. tree prior, and related models, are sometimes known as `coalescent priors'.

We now present an overview of coalescent theory and its implementation as a tree prior in the form of the Bayesian skyline.

It is natural to consider evolutionary trees as being created by a `branching process'. However, the insight of coalescent theory is to consider a stochastic process in the opposite direction, starting with an initial set of lineages and moving backwards until they have all merged into a single lineage -- a `coalescent process'.

We will first consider how the coalescent process applies to just two lineages. They coalesce at a time depth drawn from an exponential distribution with mean $\theta$. In coalescent theory, this parameter is typically known as the `population', because in the biological context within which the theory was devised it is proportional to the size of the breeding population of the community of organisms in question. In the context of phylolinguistics it is perhaps best understood as simply being the inverse of the rate of coalescence.

When we have more than two lineages, each pair of lineages has a chance of coalescing according to this same distribution. Therefore, given $k$ lineages, the overall rate of coalescent events increases by a factor of $^{k}C_2$. Therefore the probability distribution for the time depth of the next coalescent event is the following:

\begin{equation}\label{eqn:coalescent}
Pr(t) = Exp\left(\frac{\binom{k}{2}}{\theta}\right) = \frac{k(k-1)}{2\theta} \cdot e^{-\frac{k(k-1)}{2\theta} t}
\end{equation}

Assume we have a dated phylogenetic tree $\psi$ with all $n$ tips positioned at time $t=0$. Then, moving backwards through time, we can divide its chronology into $n - 1$ intervals, with the first interval starting at $t=0$, and each interval ending at a coalescent event (of which there are necessarily $n-1$). Then every interval has some width $w_i$, which can be considered to be the time spent awaiting the coalescent event for that interval. Each interval also has a certain number of lineages, $k_i$ (which is clearly $n$ for the first interval, $n - 1$ for the second, and so on down to $2$ lineages for the final interval). We also associate some population parameter $\theta_i$ with each interval, which we collectively refer to as $\Theta$. Then it is reasonably intuitive to see that, following on from \eqref{eqn:coalescent}, the likelihood of $\psi$ is the following:

\begin{equation}\label{eqn:skyline}
Pr(\psi\;|\;\Theta) = \prod_{i = 1}^{n - 1}\; \frac{k_i(k_i-1)}{2\theta_i} \cdot e^{-\frac{k_i(k_i-1)}{2\theta_i} w_i}
\end{equation}

This is the `classic skyline plot'. There are only two added complexities that modify this model into the `generalised skyline plot' that is implemented in \textit{Dyr}. The first is that instead of selecting $n - 1$ values of $\theta$, we select $s$ values, where $s$ is a consideraly smaller number; typically $5$.\footnote{This value is pre-selected and not inferred by MCMC. The reader may fairly ask why; the reason is that changing $s$ changes the size of the parameter space. Stepping through variably-sized parameter spaces requires a considerably more complicated variant of MCMC called `reversible-jump'. This technique is not used by most phylolinguistic research and is consequently out-of-scope for our project.} We then group the $n - 1$ coalescent intervals into $s$ contiguous `generalised intervals' to which the $\theta$ values correspondingly apply. This is to prevent the population values being too heavily influenced by stochastical noise. The other necessary modfication is to allow for the number of lineages to change within a coalescent interval. I spare the reader the fiddly notation for these amendments since the underlying maths remains essentially the same.

The parameters of the generalised skyline plot that are inferred by the MCMC process are the sizes of the generalised intervals, $\Xi$, and the `population' parameters $\Theta$. Thus, for inferences using this tree prior, $\omega = (\Xi, \Theta)$. The parameters $\Xi$ have a uniform prior (with the proviso that all generalised intervals must contain at least one coalescent interval). However, $\Theta$ has the following scale-invariant prior, which applies population smoothing between adjacent generalised intervals.\footnote{This equation is slightly different to that given by Drummond et al. -- I believe theirs to be erroneous.}

\begin{equation}\label{eqn:thetaprior}
    f(\Theta) = \frac{1}{\theta_1} \; \prod_{j=2}^s\; \frac{1}{\theta_{j-1}} \cdot e^{-\frac{\theta_j}{\theta_{j-1}}}
\end{equation}

For inferences using the generalised skyline plot, equation \eqref{eqn:thetaprior} effectively corresponds to $f(\omega)$ in \eqref{eqn:posterior}.

\subsubsection{Tree Prior Suitability}

We have chosen to implement the generalised skyline plot because it is the standard choice of tree prior for phylolinguistic inference. This is in spite of the fact that the theory underlying it does not have a convincing linguistic interpretation. Coalescent theory is predicated on a large population of individuals, inter-breeding at random, of which only a relatively tiny fraction are sampled. This makes sense in a bioinformatics context; most likely your dataset does not include an appreciable fraction of all the organisms in a species! However, in a linguistics context, this assumption does not hold up -- our broad dataset for Indo-European contains 94 languages, a non-trivial proportion of all Indo-European languages ever to exist (even with a liberal approach to the language-or-dialect question). It is also hard to reconcile our basic intuitions about language evolution with the stipulations of coalescent theory; in particular, that a population be haploid (languages don't always cleanly displace each other) and mate randomly (suggesting a reason why Tajik has had little influence on Icelandic is left as an exercise to the reader).

Rama is to my knowledge the only researcher to admit that the coalescent prior is hard to interpret in a linguistic context. He half-heartedly suggests that the observed languages are a sample of a larger haploid population of languages. This cannot, however, be reconciled with our knowledge that our Indo-European dataset comprises a reasonably large fraction of all the Indo-European languages spoken today (and, most likely, all those ever spoken). Rama also does not offer a suggestion to solve the random-breeding problem.

In my view, it is best to simply treat the troublesome `population' parameter as simply being an inferred `inverse rate of coalescence' and leave it at that. In this context, it is probably more sensible to use a constant-population coalescent prior (as Rama does) rather than the generalised skyline plot that is more generally preferred. Coalescent priors do nonetheless have some sensible properties, in particular that the rate of coalescence is proportional to the number of lineages. This means we can treat coalescence as a local phenomena, which is obviously desirable. The likelihood of a particular language diverging is very clearly not influenced by another language two continents away splitting in twain. This might sound too obvious to need stating, but it is a property not shared with the uniform prior, which Rama suggests as a viable alternative. This prior model assumes that coalescent events are evenly distributed between the root and the present day, which sounds sensible until one realises the implication that the likelihood of any given lineage diverging is reduced when the overall number of lineages increases.

An alternative to the dubiously justified coalescent prior and the demonstrably inappropriate uniform prior is the fossilised birth death (FBD) prior. A relatively new model, this prior has support for `fossilisation' -- i.e. ancestral languages -- and while it is unclear how cleanly the FBD prior's notion of fossilisation can be mapped onto the linguistic notion of dead language attestation, in principle this tree prior may offer a more elegant alternative to the coalescent prior with ancestry constraints. We have not implemented it because it is considerably more complicated than the generalised skyline plot and the uniform prior, and because it remains comparatively little-used for phylolinguistics. However our hope is that  \textit{Dyr} can serve as a worthy platform for implementing promising methods like the FBD prior in future research.

Another point of contention is the suitability of constraints. Rama opts not to employ clade or ancestry constraints. In the former case, he suggests that they are unnecessary because his consensus trees feature the desired clades anyway. However, a consequence of not using clade constraints is that a non-zero subset of the posterior distribution is irreconcilable with our prior knowledge of the evolution of Indo-European. If the posterior is partially invalid then the median values derived from the posterior, including the critical root age, are also to some extent invalid. Rama uses the uniform and FBD priors without ancestry constraints and infers root ages similar to those achieved by Chang et al. under the coalescent prior with ancestry constraints. However, this does not negate the fundamental need for ancestry constraints (or something like them) to produce a posterior distribution that meaningfully corresponds to linguistic reality. Fundamentally, an inference that produces trees that do not have a sensible correspondance to our understanding of how a language family has developed historically cannot be used to draw novel conclusions.

\subsubsection{Substitution Model Priors}

We now come to the final term in equation \eqref{eqn:posterior}: $f(\lambda)$, the prior likelihood of the parameterisation of the substitution model. $f(\lambda)$ is computed as the product of the individual prior distributions on each of the parameters in $\lambda$.

The stationary frequency $\pi_1$ has a uniform prior distribution on the range $(0, 1)$.

For the base rate, $\mu$, we employ a `reciprocal' prior, $f(\mu) \propto \mu^{-1}$, which we derive from Chang et al. Such a prior is typical in phylolinguistic inference. Rama instead uses an exponential prior, which confusingly, he seems to change the parameterisation of depending on his tree prior. The arbitrariness of this approach dissuaded us from adopting it.

The shape parameters for among-site and among-branch rate variation, $\alpha$ and $\beta$, are both assigned a prior likelihood proportional to the exponential distribution $Exp(2.5)$, with mean $0.4$. This relatively unopinionated prior is also derived from Chang et al. We impose no prior distribution on $\phi$, the assignment of branch-rates to branches.

\subsubsection{Summary}

We have now discussed every aspect of our likelihood model. We have described the procedure for evaluating the likelihood of a set of trait data $x$ under a specified likelihood model, given $\Gamma$, a complete parameterisation for that model -- consisting of a dated phylogeny $\psi$, a tree prior parameterisation $\omega$, and a substitution model parameterisation $\lambda$. We have also outlined the choices of prior distributions for these parameters. We now move on to the matter of searching through the space of $\Gamma$.

\subsection{Markov Chain Monte Carlo}

As we have shown, we can calculate the posterior likelihood $f(\Gamma\,|\,x)$ for any given parameterisation $\Gamma$. However, the size of the parameter space makes this function effectively a black-box. Without some method for determining the shape of the distribution and in particular the region of maximal density it is not useful to us. Our approach for interrogating this distribution is to use a stochastic process called Markov Chain Monte Carlo (MCMC).

All MCMC methods produce a randomly generated sequence of states, such that each state is either equal to the state before or is an augmentation of the previous state. We design our MCMC chain such that the distribution of the states in the chain asymptoptically approaches the distribution which we wish to approximate. This is achieved by using the likelihood function of the desired distribution to determine the probability of an augmented state being accepted into the chain. Of course, for our purposes, the likelihood function is that of the posterior distribution $f(\Gamma\,|\,x)$, and each state encodes some parameterisation $\Gamma$.  


\subsubsection{Metropolis-Hastings Algorithm}

Strictly speaking, Markov Chain Monte Carlo is a family of different stochastic methods; the one we employ is known as the `Metropolis-Hastings algorithm'. A description of this algorithm is given below.

\begin{equation*}
acc(\Gamma, \Gamma^*) := min\left\{\frac{f(\Gamma^*|\,x)}{f(\;\Gamma\,|\,x)} \cdot \frac{q(\;\Gamma\,|\,\Gamma^*)}{q(\Gamma^*|\;\Gamma\,)},\;1\,\right\}
\end{equation*}

\indent\textbf{input} initial state $\Gamma_0$

\indent\textbf{for} $i := 1, 2, \ldots , n$ \textbf{do}

%\indent\indent \textbf{let} $\Gamma_i = \Gamma'$

%\indent\indent \textbf{while} not $\mathrm{accept}$:

\indent\indent\textbf{sample} $\Gamma'$ \textbf{from} $q(\Gamma^*|\,\Gamma_{i-1})$

\indent\indent\textbf{if} $acc(\Gamma_{i-1}, \Gamma') \ge (u \sim [0, 1])$ \textbf{then}

\indent\indent\indent\textbf{let} $\Gamma_i = \Gamma'$

\indent\indent\textbf{else}

\indent\indent\indent\textbf{let} $\Gamma_i = \Gamma_{i-1}$

\indent\indent\textbf{end}

\indent\textbf{end}

\vspace{0.5cm}

The algorithm starts with an initial parameterisation, $\Gamma_0$. The specific nature of this state is not terribly important, other than that it should have non-zero posterior likelihood.

For each iteration of the algorithm, $i$, a novel parameterisation $\Gamma'$ is drawn from a distribution $q$, which is `centred' on the previous state $\Gamma_{i-1}$. We call $q$ the `proposal distribution'. We then calculate the acceptance probability $a = acc(\Gamma_{i-1}, \Gamma') \in [0, 1]$. With probability $a$ we choose $\Gamma'$ as the state for this iteration $\Gamma_i$ -- otherwise we reject $\Gamma'$ and instead copy over the previous state $\Gamma_{i-1}$.

The core of the function $acc(\Gamma, \Gamma^*)$ is the multiplication of two ratios. The first is the ratio of the posterior likelihood of $\Gamma^*$ to that of $\Gamma$. If it is greater than $1$, then $\Gamma^*$ is considered the more likely parameterisation, while if it is less than $1$ then $\Gamma$ is considered more likely. The second ratio is called the `Hastings ratio'. It is the ratio of the likelihood of $\Gamma$ in the proposal ratio of $\Gamma^*$ to the likelihood of $\Gamma^*$ in the proposal ratio of $\Gamma$. Intuitively this can be thought of as `backward-step chance over forward-step chance'. Without this term, the Markov Chain would `slide away' from the desired equilibrium distribution with a bias towards those states that the proposal distribution is more likely to `step towards' than `step away from'.

Excepting the vanishingly unlikely scenario that the initial state $\Gamma_0$ is close to the global likelihood maxima, we can be certain that the initial states of the chain will not be a good approximation for the posterior distribution. Therefore, in our analyses, we discard them, instead sampling from the latter part of the chain. Formally speaking, the bias induced by the initial state is never wholly eliminated, but with a good MCMC implementation it becomes negligable.

\section{Implementation}

In implementing \textit{Dyr}, we sought to build a software system that was high-performance, elegantly designed, and easily extensible.

Of course, as with all software, the first and most fundamental implementation decision was the choice of programming language. We opted to use Rust, a modern systems programming language, due to its high-performance, emphasis on memory-safety, and ergonomic type system.

The design of \textit{Dyr} was inspired in part by Paul O. Lewis' Strom project, which sets an excellent example for how to write phylogenetic inference software.

Following the example of Strom, BEAST, and MrBayes, \textit{Dyr} uses the open-source library BEAGLE 3 to perform the core likelihood calculations required by Felsenstein's algorithm. This library supports a high-performance CUDA backend, allowing likelihood calculations to be highly parallelised and executed on Nvidia graphics cards. However, BEAGLE is very low-level; it has no conception of trees, nodes, or taxa, instead dealing only with partial likelihood buffers and transition matrices. It is therefore the responsibility of the calling program to keep track of the correspondance between higher level data-structures and BEAGLE buffer indexes, and to determine the necessary operations to re-calculate the marginal likelihood when the parameterisation is augmented.

The user inferface of \textit{Dyr} is through the command-line. An inference run is fully specified by a file called a `manifest' and a NEXUS file containing trait data. Program output, which is also configurable within the manifest, is printed to stdout.

\subsection{Program Structure}

The structure of \textit{Dyr} is outlined in the diagram below. The system is composed of three layers: \textit{Dyr} itself, providing the user-facing interface; \textit{Fitzroy},\footnote{Robert FitzRoy was the captain of the expeditionary ship HMS Beagle, whose voyage was chronicled by Charles Darwin. Later a pioneering meteorologist, the shipping forecast region Finisterre was renamed in FitzRoy's honour in 2002.} providing the phylogenetic logic and inference engine; and \textit{Beagle}, handling core likelihood calculations. This high-level structure is demonstrated in the diagram below.

\vspace{0.4cm}
\includegraphics[width=8.9cm]{progdiagram}
\vspace{0.4cm}

When \textit{Dyr} runs, the first order-of-duty is to build a \texttt{DyrConfig} structure which encodes all the information necessary to perform an inference run. This is then used to instantiate a \texttt{fitzroy::MCMC} structure, which is composed of three key parts: the \texttt{Configuration}, which describes the immutable `framework' of the parameter space; the mutable \texttt{Parameters}, which are equivalent to $\Gamma$ in our earlier discussion; and the structure \texttt{Propose}, which stores the proposal distribution. The initial \texttt{Parameters} are drawn at random; care is taken to ensure they have non-zero prior likelihood, but otherwise no attempt is made to choose `good' parameters.

Before starting the Markov Chain, \textit{Dyr} also creates a blank \texttt{fitzroy::Summary} structure, which will serve as a database for intermittently snapshotted phylogenies once the burn-in period of the chain has elapsed. 

The program now enters the main-loop of the Metropolis-Hastings algorithm, which is handled by \textit{Dyr} directly. It calls the \texttt{step} function of its \texttt{fitzroy::MCMC} instance, and on most iterations this is all it does. However, at regular intervals, configurable in the manifest, it outputs information about the current chain state. As mentioned, in the latter part of the inference process it also takes phylogeny snapshots. These snapshots are only taken once every $1000$ steps to mitigate autocorrelation.

At the end of the inference process a Maximum Clade Crediblity (MCC) tree $\psi_{mcc}$ is calculated from the set of snapshotted trees, and output in Newick format. The topology $\tau_{mcc}$ of the tree $\psi_{mcc}$ is defined as being equal to that of the tree within the set that has the highest sum clade frequency across all its clades, where clade frequency is the number of times a given clade appears within the sample. Then, to calculate the chronology $\delta_{mcc}$ of the MCC tree, we assign each clade root (i.e. node) a date equal to the median date of that clade in the set of trees, and calculate the branch lengths by simply traversing the tree.\footnote{Astute readers will note that this could lead to negative branch lengths. This is considered an acceptable, though unlikely, outcome of the MCC algorithm.}

As it happens, our implementation of Maximum Clade Credibility kills two birds with one stone. Decomposing a tree into a list of its clades, each \texttt{Clade} uniquely identified by a hashable bitstring, is useful not only for tallying clade frequencies, but also for checking clade and ancestry constraints in the tree prior.

\subsection{A Step in the Chain}

We now take a deeper look at the \texttt{step} function of the Fitzroy MCMC implementation. This function is the heart of the entire system, since it performs a step of the Metropolis-Hastings algorithm.

\subsubsection{Making a Move}

The first task is to draw a new parameterisation from the proposal distribution of the current parameterisation. Up til now we have only spoken abstractly about this as an augmentation of the parameterisation, but in practice this is achieved by the selection and application of a `Move' from a set of available `Moves', whereby each Move describes a specific type of modfication that can be made to the parameterisation. For example, we have a move called \texttt{TreeNodeSwap}, which chooses two nodes of the tree at random and swaps their attachment points.

The selection and application of a Move is achieved with \texttt{make\_move}, an associated function of \texttt{Propose}. This structure was supplied with the \texttt{Configuration} of the inference run when it was created and therefore only choses from the set of Moves applicable to this run. For example, the move \texttt{CoalescentIntervalResize} is not relevant when there is only one generalised interval (constant-population), so it is not registered in the set of moves at instantiation.

The function \texttt{Propose::make\_move} choses a Move at random (according to a set of hand-tuned weights). In Rust terms, each Move is in fact a structure implementing the trait \texttt{Move}.\footnote{A Rust trait is equivalent to a typeclass in Haskell, and analogous, though not equivalent, to the concept of an abstract superclass in OOP languages.} Each such Move is required to have a function itself called \texttt{make\_move}. This function draws a specific augmentation from its own internal distribution, applies it to the \texttt{Parameters}, calculates the prior likelihood change and the Hastings ratio and returns them.

At this point is is worth noting that although up until now we have spoken about likelihood calculations in the conventional way, internally our software works with the natural logarithms of likelihoods, known as `log-likelihoods'. This is necessary to maintain fidelity when working with the sort of very low likelihoods that are a natural consequence of using distributions over such a large parameter space, and also has the convenient upside of reducing multiplications and divisions into additions and subtractions.

To be precise, every implementation of the function \texttt{Move::make\_move} is required to accept an immutable reference to the \texttt{Configuration} and a mutable reference to the current \texttt{Parameters}, and return a \texttt{MoveResult}, the definition of which is given below.\footnote{Actually, this isn't the real definition; I removed some Rust idiosyncracies.}

\begin{verbatim}
struct MoveResult {
    log_prior_likelihood_delta: double,
    log_hastings_ratio: double,
    revert: Revert,
    damage: Damage
}
\end{verbatim}

The \texttt{log\_prior\_likelihood\_delta} is the change in log prior likelihood, which is the log-likelihood equivalent to the prior likelihood ratio. Similarly, the \texttt{log\_hastings\_ratio} is the log-likelihood equivalent of the Hastings ratio.

\subsubsection{Accept or Reject}

The \texttt{step} function accepts the returned \texttt{MoveResult} and calls a function to calculate the new log marginal likelihood. It then determines the acceptance probability. In log-likelihood terms, this is calculated by summing the log prior likelihood delta, the log marginal likelihood delta, and the log hastings ratio. The move is then accepted if and only if the log acceptance probability is larger than the log of a uniform random variable in the range $[0, 1]$.

If the move is not accepted then we need to revert the state of the \texttt{Parameters} back to their previous state. We have devised an elegant and flexible method for achieving this. In the definition of \texttt{MoveResult} above, note that there is a field \texttt{revert} of type \texttt{Revert}. The type \texttt{Revert} is a heap-allocated closure (anonymous function) that accepts the current state of the MCMC chain as a mutable reference. Each Move constructs a closure that closes upon the stored previous state of whichever parameter the Move augmented. If the \texttt{step} function decides to revert the Move, all it needs to do to restore the old state of the \texttt{Parameters} is to call \texttt{revert()}.

This approach is elegant and efficient. It is elegant because the step function needs to know nothing at all about any of the individual Moves; it is perfectly generic. Furthermore, the usage of a closure to encapsulate the cached state means that the Move object itself can be entirely stateless. It is efficient because the closure only stores the \texttt{Parameters} that have changed. If a Move simply alters a global rate parameter, then the tree remains is unmodified and therefore its state does not need to be cached. If this state caching was performed within the \texttt{step} function itself, its lack of knowledge about the specific move that had been made would require it to clone the entire set of \texttt{Parameters}, at considerable cost to computational and memory resources. 

If the move is accepted, the \texttt{revert} closure is never called. In any case, after having accepted or rejected the proposed parameterisation, the \texttt{step} function concludes: one iteration of Metropolis-Hastings has been completed.


\subsubsection{Marginal Likelihood}
  
Although it is easily the most computationally intensive part of the inference process, we have only so far touched upon the calculation of log marginal likelihood. As discussed, the core heavy-lifting is performed by the BEAGLE 3 library. Making this library usable and ergonomic in Rust is achieved through three abstraction layers. 

The first is the raw Rust bindings to the BEAGLE C API. These are auto-generated by the Rust library `bindgen'. The second is the low-level wrapper interface. This interface still exposes essentially the same functions, but it provides a translation layer between Rust types and C types. For example the C type \texttt{*double}, a potentially null 64-bit float pointer, corresponds to an \texttt{Option<\&mut f64>} -- an algebraic type that can optionally store a mutable reference to 64-bit float. These two layers constitute \texttt{libhmsbeagle-sys} -- a safe and usable, though unidiomatic, Rust binding to BEAGLE.

The third abstraction layer, \texttt{libhmsbeagle-rs}, consumes the interface provided by \texttt{libhmsbeagle-sys}, and in turn exposes a powerful and idiomatic Rust reimagining of BEAGLE's core interface. It wraps BEAGLE's instance API in an RAII \texttt{Instance} structure. This means that for as long as an \texttt{Instance} is allocated in memory, it corresponds to a valid and live instance within BEAGLE.

However, the most powerful abstraction that the \texttt{Instance} structure provides is what we refer to as 'buffer alternates'. To understand this feature, we must first recall the two basic datastructures upon which BEAGLE operates: partial likelihood buffers, or 'partials' for short; and transition matrix buffers, or simply 'matrices'. Every internal node of the phylogeny requires a corresponding partials buffer, while every node except for the root requires a corresponding transition matrix. When 'buffer alternates' are enabled, our system allocates two partials for each internal node and two matrices for each node excepting the root. These are known as `main' and `alternate' buffers. For each pair of buffers, we maintain a boolean flag in a structure called \texttt{Alternates} which signals which of the main and alternates buffer is currently active. Therefore, when we update a node's matrix, or re-calculate its partials, we do so using the active buffers.

To demonstrate what the benefit of all this additonal book-keeping is, we must explain the purpose of the final parameter of the \texttt{MoveResult} structure, \texttt{damage}. Each Move is obliged to create a \texttt{Damage} object, which records the matrices and partials which have been invalidated by its augmentation to the \texttt{Parameters}. Notably, if any partial is invalidated, all partials between it and the root are necessarily also invalidated, so the \texttt{Damage} structure has an associated function \texttt{mark\_partials\_to\_root}. When a Move has been made, the \texttt{step} function calls a function \texttt{flip\_by\_damage}, which switches all the partials and matrices which have been `damaged' (i.e. invalidated) onto their other buffer, be that the main or the alternate.

Having flipped the appropriate buffers, the \texttt{step} function calculates the new log marginal likelihood. Again using the \texttt{Damage} as a reference, an array of new likelihood operations is built and passed to BEAGLE. Each operation corresponds to a single step of Felsenstein's algorithm; involving only a node and its two children. This ensures that no more than the minimum amount of computation necessary to compute the new log marginal likelihood is performed.

\section{Results}

\subsection{Comparison with Other Research}

\subsection{Performance Analysis}

\section{Evaluation and Future Steps}

\section{Conclusion}

\newpage

\bibliographystyle{ieeetran}
\bibliography{dyr}

\end{document}
